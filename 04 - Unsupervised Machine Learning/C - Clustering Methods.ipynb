{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 4, Part c: Clustering Methods LAB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Methods Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This lab uses a dataset on wine quality. The data set contains various chemical properties of wine, such as acidity, sugar, pH, and alcohol. It also contains a quality metric (3-9, with highest being better) and a color (red or white). The name of the file is `Wine_Quality_Data.csv`.\n",
    "\n",
    "We will be using the chemical properties (i.e. everything but quality and color) to cluster the wine. Though this is unsupervised learning, there are interesting semi-supervised extensions relating clustering results onto color and quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import seaborn as sns, pandas as pd, numpy as np\n",
    "import os\n",
    "os.chdir('/users/salahkaf/desktop/Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns, os\n",
    "from colorsetup import colors, palette\n",
    "sns.set_palette(palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "*   Import the data and examine the features.\n",
    "*   Note which are continuous, categorical, and boolean.\n",
    "*   How many entries are there for the two colors and range of qualities?\n",
    "*   Make a histogram plot of the quality for each of the wine colors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T12:10:48.585240Z",
     "start_time": "2017-03-20T08:10:48.548076-04:00"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Area</th>\n",
       "      <td>28395</td>\n",
       "      <td>28734</td>\n",
       "      <td>29380</td>\n",
       "      <td>30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perimeter</th>\n",
       "      <td>610.291</td>\n",
       "      <td>638.018</td>\n",
       "      <td>624.11</td>\n",
       "      <td>645.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <td>208.178117</td>\n",
       "      <td>200.524796</td>\n",
       "      <td>212.82613</td>\n",
       "      <td>210.557999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <td>173.888747</td>\n",
       "      <td>182.734419</td>\n",
       "      <td>175.931143</td>\n",
       "      <td>182.516516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AspectRation</th>\n",
       "      <td>1.197191</td>\n",
       "      <td>1.097356</td>\n",
       "      <td>1.209713</td>\n",
       "      <td>1.153638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eccentricity</th>\n",
       "      <td>0.549812</td>\n",
       "      <td>0.411785</td>\n",
       "      <td>0.562727</td>\n",
       "      <td>0.498616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ConvexArea</th>\n",
       "      <td>28715</td>\n",
       "      <td>29172</td>\n",
       "      <td>29690</td>\n",
       "      <td>30724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EquivDiameter</th>\n",
       "      <td>190.141097</td>\n",
       "      <td>191.272751</td>\n",
       "      <td>193.410904</td>\n",
       "      <td>195.467062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extent</th>\n",
       "      <td>0.763923</td>\n",
       "      <td>0.783968</td>\n",
       "      <td>0.778113</td>\n",
       "      <td>0.782681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solidity</th>\n",
       "      <td>0.988856</td>\n",
       "      <td>0.984986</td>\n",
       "      <td>0.989559</td>\n",
       "      <td>0.976696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roundness</th>\n",
       "      <td>0.958027</td>\n",
       "      <td>0.887034</td>\n",
       "      <td>0.947849</td>\n",
       "      <td>0.903936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Compactness</th>\n",
       "      <td>0.913358</td>\n",
       "      <td>0.953861</td>\n",
       "      <td>0.908774</td>\n",
       "      <td>0.928329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.006979</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>0.007017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.003215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <td>0.834222</td>\n",
       "      <td>0.909851</td>\n",
       "      <td>0.825871</td>\n",
       "      <td>0.861794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShapeFactor4</th>\n",
       "      <td>0.998724</td>\n",
       "      <td>0.99843</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>0.994199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>SEKER</td>\n",
       "      <td>SEKER</td>\n",
       "      <td>SEKER</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0           1           2           3\n",
       "Area                  28395       28734       29380       30008\n",
       "Perimeter           610.291     638.018      624.11     645.884\n",
       "MajorAxisLength  208.178117  200.524796   212.82613  210.557999\n",
       "MinorAxisLength  173.888747  182.734419  175.931143  182.516516\n",
       "AspectRation       1.197191    1.097356    1.209713    1.153638\n",
       "Eccentricity       0.549812    0.411785    0.562727    0.498616\n",
       "ConvexArea            28715       29172       29690       30724\n",
       "EquivDiameter    190.141097  191.272751  193.410904  195.467062\n",
       "Extent             0.763923    0.783968    0.778113    0.782681\n",
       "Solidity           0.988856    0.984986    0.989559    0.976696\n",
       "roundness          0.958027    0.887034    0.947849    0.903936\n",
       "Compactness        0.913358    0.953861    0.908774    0.928329\n",
       "ShapeFactor1       0.007332    0.006979    0.007244    0.007017\n",
       "ShapeFactor2       0.003147    0.003564    0.003048    0.003215\n",
       "ShapeFactor3       0.834222    0.909851    0.825871    0.861794\n",
       "ShapeFactor4       0.998724     0.99843    0.999066    0.994199\n",
       "Class                 SEKER       SEKER       SEKER       SEKER"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "# Import the data\n",
    "data = pd.read_csv(\"Dry_Bean.csv\")\n",
    "\n",
    "data.head(4).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T12:09:58.538878Z",
     "start_time": "2017-03-20T08:09:58.531714-04:00"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13611, 17)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data types for each entry. The implementation of K-means in Scikit-learn is designed only to work with continuous data (even though it is sometimes used with categorical or boolean types). Fortunately, all the columns we will be using (everything except quality and color) are continuous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T12:12:23.585637Z",
     "start_time": "2017-03-20T08:12:23.576416-04:00"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area                 int64\n",
       "Perimeter          float64\n",
       "MajorAxisLength    float64\n",
       "MinorAxisLength    float64\n",
       "AspectRation       float64\n",
       "Eccentricity       float64\n",
       "ConvexArea           int64\n",
       "EquivDiameter      float64\n",
       "Extent             float64\n",
       "Solidity           float64\n",
       "roundness          float64\n",
       "Compactness        float64\n",
       "ShapeFactor1       float64\n",
       "ShapeFactor2       float64\n",
       "ShapeFactor3       float64\n",
       "ShapeFactor4       float64\n",
       "Class               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of entries for each wine color.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T12:10:32.347631Z",
     "start_time": "2017-03-20T08:10:32.337545-04:00"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DERMASON    3546\n",
       "SIRA        2636\n",
       "SEKER       2027\n",
       "HOROZ       1928\n",
       "CALI        1630\n",
       "BARBUNYA    1322\n",
       "BOMBAY       522\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of quality values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T13:00:49.509254Z",
     "start_time": "2017-03-20T09:00:49.495394-04:00"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data.quality.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the histogram.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T13:05:20.809064Z",
     "start_time": "2017-03-20T09:05:20.584910-04:00"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# seaborn styles\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white')\n",
    "\n",
    "# custom colors\n",
    "red = sns.color_palette()[2]\n",
    "white = sns.color_palette()[4]\n",
    "\n",
    "# set bins for histogram\n",
    "bin_range = np.array([3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "# plot histogram of quality counts for red and white wines\n",
    "ax = plt.axes()\n",
    "for color, plot_color in zip(['red', 'white'], [red, white]):\n",
    "    q_data = data.loc[data.color==color, 'quality']\n",
    "    q_data.hist(bins=bin_range, \n",
    "                alpha=0.5, ax=ax, \n",
    "                color=plot_color, label=color)\n",
    "    \n",
    "\n",
    "ax.legend()\n",
    "ax.set(xlabel='Quality', ylabel='Occurrence')\n",
    "\n",
    "# force tick labels to be in middle of region\n",
    "ax.set_xlim(3,10)\n",
    "ax.set_xticks(bin_range+0.5)\n",
    "ax.set_xticklabels(bin_range);\n",
    "ax.grid('off')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "*   Examine the correlation and skew of the relevant variables--everything except color and quality (without dropping these columns from our data).\n",
    "*   Perform any appropriate feature transformations and/or scaling.\n",
    "*   Examine the pairwise distribution of the variables with pairplots to verify scaling and normalization efforts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "float_columns = [x for x in data.columns if x not in ['color', 'quality']]\n",
    "\n",
    "# The correlation matrix\n",
    "corr_mat = data[float_columns].corr()\n",
    "\n",
    "# Strip out the diagonal values for the next step\n",
    "for x in range(len(float_columns)):\n",
    "    corr_mat.iloc[x,x] = 0.0\n",
    "    \n",
    "corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Pairwise maximal correlations\n",
    "corr_mat.abs().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And an examination of the skew values in anticipation of transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "skew_columns = (data[float_columns]\n",
    "                .skew()\n",
    "                .sort_values(ascending=False))\n",
    "\n",
    "skew_columns = skew_columns.loc[skew_columns > 0.75]\n",
    "skew_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Perform log transform on skewed columns\n",
    "for col in skew_columns.index.tolist():\n",
    "    data[col] = np.log1p(data[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform feature scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "data[float_columns] = sc.fit_transform(data[float_columns])\n",
    "\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the pairplot of the transformed and scaled features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sns.set_context('notebook')\n",
    "sns.pairplot(data[float_columns + ['color']], \n",
    "             hue='color', \n",
    "             hue_order=['white', 'red'],\n",
    "             palette={'red':red, 'white':'gray'});\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "*   Fit a K-means clustering model with two clusters.\n",
    "*   Examine the clusters by counting the number of red and white wines in each cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T01:59:09.017663Z",
     "start_time": "2017-03-19T21:59:08.896993-04:00"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "### BEGIN SOLUTION\n",
    "km = KMeans(n_clusters=2, random_state=42)\n",
    "km = km.fit(data[float_columns])\n",
    "\n",
    "data['kmeans'] = km.predict(data[float_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T01:59:09.332043Z",
     "start_time": "2017-03-19T21:59:09.315410-04:00"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "(data[['color','kmeans']]\n",
    " .groupby(['kmeans','color'])\n",
    " .size()\n",
    " .to_frame()\n",
    " .rename(columns={0:'number'}))\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "*   Now fit K-Means models with cluster values ranging from 1 to 20.\n",
    "*   For each model, store the number of clusters and the inertia value.\n",
    "*   Plot cluster number vs inertia. Does there appear to be an ideal cluster number?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T01:59:21.588328Z",
     "start_time": "2017-03-19T21:59:12.450288-04:00"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# Create and fit a range of models\n",
    "km_list = list()\n",
    "\n",
    "for clust in range(1,21):\n",
    "    km = KMeans(n_clusters=clust, random_state=42)\n",
    "    km = km.fit(data[float_columns])\n",
    "    \n",
    "    km_list.append(pd.Series({'clusters': clust, \n",
    "                              'inertia': km.inertia_,\n",
    "                              'model': km}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T01:59:21.775524Z",
     "start_time": "2017-03-19T21:59:21.589747-04:00"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plot_data = (pd.concat(km_list, axis=1)\n",
    "             .T\n",
    "             [['clusters','inertia']]\n",
    "             .set_index('clusters'))\n",
    "\n",
    "ax = plot_data.plot(marker='o',ls='-')\n",
    "ax.set_xticks(range(0,21,2))\n",
    "ax.set_xlim(0,21)\n",
    "ax.set(xlabel='Cluster', ylabel='Inertia');\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "*   Fit an agglomerative clustering model with two clusters.\n",
    "*   Compare the results to those obtained by K-means with regards to wine color by reporting the number of red and white observations in each cluster for both K-means and agglomerative clustering.\n",
    "*   Visualize the dendrogram produced by agglomerative clustering. *Hint:* SciPy has a module called [`cluster.hierarchy`](https://docs.scipy.org/doc/scipy/reference/cluster.hierarchy.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2022-01-01#module-scipy.cluster.hierarchy) that contains the `linkage` and `dendrogram` functions required to create the linkage map and plot the resulting dendrogram.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T11:30:31.254165Z",
     "start_time": "2017-03-20T07:30:27.894864-04:00"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "### BEGIN SOLUTION\n",
    "ag = AgglomerativeClustering(n_clusters=2, linkage='ward', compute_full_tree=True)\n",
    "ag = ag.fit(data[float_columns])\n",
    "data['agglom'] = ag.fit_predict(data[float_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that cluster assignment is arbitrary, the respective primary cluster numbers for red and white may not be identical to the ones below and also may not be the same for both K-means and agglomerative clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T11:46:08.938224Z",
     "start_time": "2017-03-20T07:46:08.924114-04:00"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# First, for Agglomerative Clustering:\n",
    "(data[['color','agglom','kmeans']]\n",
    " .groupby(['color','agglom'])\n",
    " .size()\n",
    " .to_frame()\n",
    " .rename(columns={0:'number'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing with KMeans results:\n",
    "(data[['color','agglom','kmeans']]\n",
    " .groupby(['color','kmeans'])\n",
    " .size()\n",
    " .to_frame()\n",
    " .rename(columns={0:'number'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing results:\n",
    "(data[['color','agglom','kmeans']]\n",
    " .groupby(['color','agglom','kmeans'])\n",
    " .size()\n",
    " .to_frame()\n",
    " .rename(columns={0:'number'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the cluster numbers are not identical, the clusters are very consistent within a single wine variety (red or white).\n",
    "\n",
    "And here is a plot of the dendrogram created from agglomerative clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T11:53:03.838928Z",
     "start_time": "2017-03-20T07:53:02.088506-04:00"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# First, we import the cluster hierarchy module from SciPy (described above) to obtain the linkage and dendrogram functions.\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "Z = hierarchy.linkage(ag.children_, method='ward')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "\n",
    "# Some color setup\n",
    "red = colors[2]\n",
    "blue = colors[0]\n",
    "\n",
    "hierarchy.set_link_color_palette([red, 'gray'])\n",
    "\n",
    "den = hierarchy.dendrogram(Z, orientation='top', \n",
    "                           p=30, truncate_mode='lastp',\n",
    "                           show_leaf_counts=True, ax=ax,\n",
    "                           above_threshold_color=blue)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "In this question, we are going to explore clustering as a form of feature engineering.\n",
    "\n",
    "*   Create a **binary** target variable `y`, denoting if the quality is greater than 7 or not.\n",
    "*   Create a variable called `X_with_kmeans` from `data`, by dropping the columns \"quality\", \"color\" and \"agglom\" from the dataset. Create `X_without_kmeans` from that by dropping \"kmeans\".\n",
    "*   For both datasets, using **[StratifiedShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2022-01-01)** with 10 splits, fit 10 Random Forest Classifiers and find the mean of the ROC-AUC scores from these 10 classifiers.\n",
    "*   Compare the average roc-auc scores for both models, the one using the KMeans cluster as a feature and the one that doesn't use it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "y = (data['quality'] > 7).astype(int)\n",
    "X_with_kmeans = data.drop(['agglom', 'color', 'quality'], axis=1)\n",
    "X_without_kmeans = X_with_kmeans.drop('kmeans', axis=1)\n",
    "sss = StratifiedShuffleSplit(n_splits=10, random_state=6532)\n",
    "\n",
    "def get_avg_roc_10splits(estimator, X, y):\n",
    "    roc_auc_list = []\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        estimator.fit(X_train, y_train)\n",
    "        y_predicted = estimator.predict(X_test)\n",
    "        y_scored = estimator.predict_proba(X_test)[:, 1]\n",
    "        roc_auc_list.append(roc_auc_score(y_test, y_scored))\n",
    "    return np.mean(roc_auc_list)\n",
    "# return classification_report(y_test, y_predicted)\n",
    "\n",
    "estimator = RandomForestClassifier()\n",
    "roc_with_kmeans = get_avg_roc_10splits(estimator, X_with_kmeans, y)\n",
    "roc_without_kmeans = get_avg_roc_10splits(estimator, X_without_kmeans, y)\n",
    "print(\"Without kmeans cluster as input to Random Forest, roc-auc is \\\"{0}\\\"\".format(roc_without_kmeans))\n",
    "print(\"Using kmeans cluster as input to Random Forest, roc-auc is \\\"{0}\\\"\".format(roc_with_kmeans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now explore if the number of clusters have an effect in this improvement.\n",
    "\n",
    "*   Create the basis training set from `data` by restricting to float_columns.\n",
    "*   For $n = 1, \\ldots, 20$, fit a KMeans algorithim with $n$ clusters. **[One-hot encode]()** it and add it to the **basis** training set. Don't add it to the previous iteration.\n",
    "*   Fit 10 **Logistic Regression** models and compute the average roc-auc-score.\n",
    "*   Plot the average roc-auc scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_basis = data[float_columns]\n",
    "sss = StratifiedShuffleSplit(n_splits=10, random_state=6532)\n",
    "\n",
    "def create_kmeans_columns(n):\n",
    "    km = KMeans(n_clusters=n)\n",
    "    km.fit(X_basis)\n",
    "    km_col = pd.Series(km.predict(X_basis))\n",
    "    km_cols = pd.get_dummies(km_col, prefix='kmeans_cluster')\n",
    "    return pd.concat([X_basis, km_cols], axis=1)\n",
    "\n",
    "estimator = LogisticRegression()\n",
    "ns = range(1, 21)\n",
    "roc_auc_list = [get_avg_roc_10splits(estimator, create_kmeans_columns(n), y)\n",
    "                for n in ns]\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.plot(ns, roc_auc_list)\n",
    "ax.set(\n",
    "    xticklabels= ns,\n",
    "    xlabel='Number of clusters as features',\n",
    "    ylabel='Average ROC-AUC over 10 iterations',\n",
    "    title='KMeans + LogisticRegression'\n",
    ")\n",
    "ax.grid(True)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
