{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part g: Transfer Learning DEMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we will use the well-known MNIST digit data. To illustrate the power and concept of transfer learning, we will train a CNN on just the digits 5,6,7,8,9.  Then we will train just the last layer(s) of the network on the digits 0,1,2,3,4 and see how well the features learned on 5-9 help with classifying 0-4.\n",
    "\n",
    "Adapted from https://github.com/fchollet/keras/blob/master/examples/mnist_transfer_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import keras\n",
    "from keras.datasets import mnist # The data set\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "#from tensorflow import keras\n",
    "#from tensorflow.keras.datasets import mnist\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "#from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "#from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 7, 30, 17, 35, 18, 159780)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#used to help some of the timing functions\n",
    "now = datetime.datetime.now\n",
    "now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some parameters to be fixed each time \n",
    "batch_size = 128 # number of images\n",
    "num_classes = 5 # [0,4] and [5,9]\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some more parameters\n",
    "img_rows, img_cols = 28, 28 # 28 pixels times 28 pixels.\n",
    "filters = 32 # depth of the kernels output\n",
    "pool_size = 2 # 2 by 2\n",
    "kernel_size = 3 # 3 by 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This just handles some variability in how the input data is loaded\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "# here we are adjusting the input shape based on the source\n",
    "# These images are gray images (depth = channel = 1)\n",
    "# if the depth of an image (channel) is first in the tuple, we will take the first shape.\n",
    "# If not, we take the second input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To simplify things, write a function to include all the training steps\n",
    "## As input, function takes a model, training set, test set, and the number of classes\n",
    "## Inside the model object will be the state about which layers we are freezing and which we are training\n",
    "\n",
    "def train_model(model, train, test, num_classes): # tain and test are tuples in this situation\n",
    "    # part 1: data egnineering\n",
    "    x_train = train[0].reshape((train[0].shape[0],) + input_shape) # Here we are pulling the first element in the tupple\n",
    "                                                                   # Then we reshape it in the form (No. images, pix, pix, depth)\n",
    "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
    "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
    "    \n",
    "    # model compiling\n",
    "    model.compile(loss='categorical_crossentropy', # multi-class classification\n",
    "                  optimizer='adadelta', # an optimizer with similar math to RMSprop\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    #model fitting\n",
    "    t = now()\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    print('Training time: %s' % (now() - t))\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# create two datasets: one with digits below 5 and one with 5 and above\n",
    "x_train_lt5 = x_train[y_train < 5]\n",
    "y_train_lt5 = y_train[y_train < 5]\n",
    "x_test_lt5 = x_test[y_test < 5]\n",
    "y_test_lt5 = y_test[y_test < 5]\n",
    "\n",
    "x_train_gte5 = x_train[y_train >= 5]\n",
    "y_train_gte5 = y_train[y_train >= 5] - 5 # subtract 5 from all the array\n",
    "x_test_gte5 = x_test[y_test >= 5]\n",
    "y_test_gte5 = y_test[y_test >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape # original shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[144]) # print the class of the image\n",
    "plt.imshow(x_train[144]); # print the image\n",
    "print(x_train[144].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the \"feature\" layers.  These are the early layers that we expect will \"transfer\"\n",
    "# to a new problem.  We will freeze these layers during the fine-tuning process\n",
    "\n",
    "feature_layers = [\n",
    "    Conv2D(filters, kernel_size,\n",
    "           padding='valid',\n",
    "           input_shape=input_shape),\n",
    "    Activation('relu'),\n",
    "    Conv2D(filters, kernel_size),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the \"classification\" layers.  These are the later layers that predict the specific classes from the features\n",
    "# learned by the feature layers.  This is the part of the model that needs to be re-trained for a new problem\n",
    "\n",
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes), # The nodes in the last hidden layer must be the same as number of classes\n",
    "    Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 17:35:18.821575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# We create our model by combining the two sets of layers as follows\n",
    "model = Sequential(feature_layers + classification_layers) # adding the lists to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 12, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               589952    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 600,165\n",
      "Trainable params: 600,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (29404, 28, 28, 1)\n",
      "29404 train samples\n",
      "4861 test samples\n",
      "Epoch 1/10\n",
      "230/230 [==============================] - 34s 144ms/step - loss: 1.6037 - accuracy: 0.2138 - val_loss: 1.5838 - val_accuracy: 0.2156\n",
      "Epoch 2/10\n",
      "230/230 [==============================] - 34s 147ms/step - loss: 1.5791 - accuracy: 0.2774 - val_loss: 1.5556 - val_accuracy: 0.4053\n",
      "Epoch 3/10\n",
      "230/230 [==============================] - 35s 150ms/step - loss: 1.5520 - accuracy: 0.3583 - val_loss: 1.5242 - val_accuracy: 0.5678\n",
      "Epoch 4/10\n",
      "230/230 [==============================] - 36s 154ms/step - loss: 1.5222 - accuracy: 0.4318 - val_loss: 1.4885 - val_accuracy: 0.6717\n",
      "Epoch 5/10\n",
      "230/230 [==============================] - 35s 152ms/step - loss: 1.4878 - accuracy: 0.4946 - val_loss: 1.4474 - val_accuracy: 0.7221\n",
      "Epoch 6/10\n",
      "230/230 [==============================] - 33s 142ms/step - loss: 1.4466 - accuracy: 0.5480 - val_loss: 1.3997 - val_accuracy: 0.7453\n",
      "Epoch 7/10\n",
      "230/230 [==============================] - 32s 138ms/step - loss: 1.4008 - accuracy: 0.5845 - val_loss: 1.3451 - val_accuracy: 0.7649\n",
      "Epoch 8/10\n",
      "230/230 [==============================] - 49s 214ms/step - loss: 1.3485 - accuracy: 0.6173 - val_loss: 1.2835 - val_accuracy: 0.7795\n",
      "Epoch 9/10\n",
      "230/230 [==============================] - 34s 150ms/step - loss: 1.2922 - accuracy: 0.6374 - val_loss: 1.2169 - val_accuracy: 0.7941\n",
      "Epoch 10/10\n",
      "230/230 [==============================] - 32s 138ms/step - loss: 1.2297 - accuracy: 0.6682 - val_loss: 1.1462 - val_accuracy: 0.8077\n",
      "Training time: 0:05:53.007657\n",
      "Test loss score: 1.1462266445159912\n",
      "Test accuracy: 0.8076527714729309\n"
     ]
    }
   ],
   "source": [
    "# Now, let's train our model on the digits 5,6,7,8,9\n",
    "\n",
    "train_model(model,\n",
    "            (x_train_gte5, y_train_gte5),\n",
    "            (x_test_gte5, y_test_gte5), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing Layers\n",
    "Keras allows layers to be \"frozen\" during the training process.  That is, some layers would have their weights updated during the training process, while others would not.  This is a core part of transfer learning, the ability to train just the last one or several layers.\n",
    "\n",
    "Note also, that a lot of the training time is spent \"back-propagating\" the gradients back to the first layer.  Therefore, if we only need to compute the gradients back a small number of layers, the training time is much quicker per iteration.  This is in addition to the savings gained by being able to train on a smaller data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze only the feature layers\n",
    "for l in feature_layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe below the differences between the number of *total params*, *trainable params*, and *non-trainable params*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 12, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               589952    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 600,165\n",
      "Trainable params: 590,597\n",
      "Non-trainable params: 9,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (30596, 28, 28, 1)\n",
      "30596 train samples\n",
      "5139 test samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 1.5384 - accuracy: 0.3494 - val_loss: 1.4687 - val_accuracy: 0.4470\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 1.4527 - accuracy: 0.4221 - val_loss: 1.3812 - val_accuracy: 0.5234\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 1.3759 - accuracy: 0.4845 - val_loss: 1.3006 - val_accuracy: 0.5941\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 10s 43ms/step - loss: 1.3078 - accuracy: 0.5424 - val_loss: 1.2261 - val_accuracy: 0.6708\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 1.2416 - accuracy: 0.6031 - val_loss: 1.1579 - val_accuracy: 0.7369\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 1.1789 - accuracy: 0.6598 - val_loss: 1.0940 - val_accuracy: 0.7832\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 1.1206 - accuracy: 0.7003 - val_loss: 1.0341 - val_accuracy: 0.8237\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 1.0680 - accuracy: 0.7435 - val_loss: 0.9775 - val_accuracy: 0.8541\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 1.0157 - accuracy: 0.7684 - val_loss: 0.9247 - val_accuracy: 0.8706\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.9692 - accuracy: 0.7910 - val_loss: 0.8754 - val_accuracy: 0.8811\n",
      "Training time: 0:01:36.092533\n",
      "Test loss score: 0.8753598928451538\n",
      "Test accuracy: 0.8811052441596985\n"
     ]
    }
   ],
   "source": [
    "train_model(model, # same model as before, we will update the last layers only.\n",
    "            (x_train_lt5, y_train_lt5),\n",
    "            (x_test_lt5, y_test_lt5), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that after a single epoch, we are already achieving results on classifying 0-4 that are comparable to those achieved on 5-9 after 5 full epochs.  This despite the fact the we are only \"fine-tuning\" the last layer of the network, and all the early layers have never seen what the digits 0-4 look like.\n",
    "\n",
    "Also, note that even though nearly all (590K/600K) of the *parameters* were trainable, the training time per epoch was still much reduced.  This is because the unfrozen part of the network was very shallow, making backpropagation faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "- Now we will write code to reverse this training process.  That is, train on the digits 0-4, then finetune only the last layers on the digits 5-9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 12, 12, 32)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               589952    \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 600,165\n",
      "Trainable params: 600,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create layers and define the model as above\n",
    "feature_layers2 = [\n",
    "    Conv2D(filters, kernel_size,\n",
    "           padding='valid',\n",
    "           input_shape=input_shape),\n",
    "    Activation('relu'),\n",
    "    Conv2D(filters, kernel_size),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]\n",
    "\n",
    "classification_layers2 = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes),\n",
    "    Activation('softmax')\n",
    "]\n",
    "model2 = Sequential(feature_layers2 + classification_layers2)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (30596, 28, 28, 1)\n",
      "30596 train samples\n",
      "5139 test samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 33s 136ms/step - loss: 1.6055 - accuracy: 0.2443 - val_loss: 1.5765 - val_accuracy: 0.3318\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 33s 137ms/step - loss: 1.5639 - accuracy: 0.3198 - val_loss: 1.5309 - val_accuracy: 0.4094\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 35s 146ms/step - loss: 1.5226 - accuracy: 0.4104 - val_loss: 1.4824 - val_accuracy: 0.6139\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 33s 137ms/step - loss: 1.4753 - accuracy: 0.5068 - val_loss: 1.4288 - val_accuracy: 0.7716\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 33s 136ms/step - loss: 1.4227 - accuracy: 0.5953 - val_loss: 1.3676 - val_accuracy: 0.8469\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 33s 137ms/step - loss: 1.3645 - accuracy: 0.6591 - val_loss: 1.2974 - val_accuracy: 0.8788\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 33s 137ms/step - loss: 1.2935 - accuracy: 0.7142 - val_loss: 1.2160 - val_accuracy: 0.8938\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 34s 143ms/step - loss: 1.2151 - accuracy: 0.7515 - val_loss: 1.1251 - val_accuracy: 0.9043\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 33s 137ms/step - loss: 1.1325 - accuracy: 0.7768 - val_loss: 1.0251 - val_accuracy: 0.9105\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 33s 137ms/step - loss: 1.0375 - accuracy: 0.8035 - val_loss: 0.9195 - val_accuracy: 0.9140\n",
      "Training time: 0:05:32.998679\n",
      "Test loss score: 0.9194972515106201\n",
      "Test accuracy: 0.9139910340309143\n"
     ]
    }
   ],
   "source": [
    "# Now, let's train our model on the digits 0,1,2,3,4\n",
    "train_model(model2,\n",
    "            (x_train_lt5, y_train_lt5),\n",
    "            (x_test_lt5, y_test_lt5), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze layers\n",
    "for l in feature_layers2:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 12, 12, 32)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               589952    \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 600,165\n",
      "Trainable params: 590,597\n",
      "Non-trainable params: 9,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (29404, 28, 28, 1)\n",
      "29404 train samples\n",
      "4861 test samples\n",
      "Epoch 1/10\n",
      "230/230 [==============================] - 10s 43ms/step - loss: 1.5942 - accuracy: 0.3014 - val_loss: 1.5286 - val_accuracy: 0.3678\n",
      "Epoch 2/10\n",
      "230/230 [==============================] - 10s 42ms/step - loss: 1.5342 - accuracy: 0.3299 - val_loss: 1.4644 - val_accuracy: 0.4116\n",
      "Epoch 3/10\n",
      "230/230 [==============================] - 10s 43ms/step - loss: 1.4720 - accuracy: 0.3777 - val_loss: 1.4041 - val_accuracy: 0.4758\n",
      "Epoch 4/10\n",
      "230/230 [==============================] - 10s 42ms/step - loss: 1.4200 - accuracy: 0.4237 - val_loss: 1.3469 - val_accuracy: 0.5513\n",
      "Epoch 5/10\n",
      "230/230 [==============================] - 10s 42ms/step - loss: 1.3689 - accuracy: 0.4754 - val_loss: 1.2933 - val_accuracy: 0.6137\n",
      "Epoch 6/10\n",
      "230/230 [==============================] - 11s 47ms/step - loss: 1.3203 - accuracy: 0.5203 - val_loss: 1.2426 - val_accuracy: 0.6628\n",
      "Epoch 7/10\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 1.2742 - accuracy: 0.5628 - val_loss: 1.1948 - val_accuracy: 0.7013\n",
      "Epoch 8/10\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 1.2321 - accuracy: 0.5996 - val_loss: 1.1496 - val_accuracy: 0.7332\n",
      "Epoch 9/10\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 1.1901 - accuracy: 0.6313 - val_loss: 1.1068 - val_accuracy: 0.7566\n",
      "Epoch 10/10\n",
      "230/230 [==============================] - 12s 51ms/step - loss: 1.1536 - accuracy: 0.6560 - val_loss: 1.0662 - val_accuracy: 0.7749\n",
      "Training time: 0:01:47.274873\n",
      "Test loss score: 1.0662267208099365\n",
      "Test accuracy: 0.7749434113502502\n"
     ]
    }
   ],
   "source": [
    "train_model(model2,\n",
    "            (x_train_gte5, y_train_gte5),\n",
    "            (x_test_gte5, y_test_gte5), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying a Different Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 26, 26, 32)        9248      \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 12, 12, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 12, 12, 32)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 328)               1511752   \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 328)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 328)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 1645      \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,532,213\n",
      "Trainable params: 1,532,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create layers and define the model as above\n",
    "feature_layers3 = [\n",
    "    Conv2D(filters, kernel_size,\n",
    "           padding='same',\n",
    "           input_shape=input_shape),\n",
    "    Activation('relu'),\n",
    "    Conv2D(filters, kernel_size),\n",
    "    Activation('relu'),\n",
    "    Conv2D(filters, kernel_size),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]\n",
    "\n",
    "classification_layers3 = [\n",
    "    Dense(328),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes),\n",
    "    Activation('softmax')\n",
    "]\n",
    "model3 = Sequential(feature_layers3 + classification_layers3)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (29404, 28, 28, 1)\n",
      "29404 train samples\n",
      "4861 test samples\n",
      "Epoch 1/10\n",
      "230/230 [==============================] - 78s 336ms/step - loss: 1.6058 - accuracy: 0.2369 - val_loss: 1.5994 - val_accuracy: 0.3425\n",
      "Epoch 2/10\n",
      "230/230 [==============================] - 78s 340ms/step - loss: 1.5967 - accuracy: 0.2864 - val_loss: 1.5881 - val_accuracy: 0.4962\n",
      "Epoch 3/10\n",
      "230/230 [==============================] - 78s 339ms/step - loss: 1.5859 - accuracy: 0.3450 - val_loss: 1.5753 - val_accuracy: 0.6095\n",
      "Epoch 4/10\n",
      "230/230 [==============================] - 1874s 8s/step - loss: 1.5731 - accuracy: 0.4018 - val_loss: 1.5600 - val_accuracy: 0.6618\n",
      "Epoch 5/10\n",
      "230/230 [==============================] - 119s 519ms/step - loss: 1.5572 - accuracy: 0.4528 - val_loss: 1.5408 - val_accuracy: 0.6892\n",
      "Epoch 6/10\n",
      "230/230 [==============================] - 135s 589ms/step - loss: 1.5373 - accuracy: 0.5060 - val_loss: 1.5159 - val_accuracy: 0.7056\n",
      "Epoch 7/10\n",
      "230/230 [==============================] - 176s 764ms/step - loss: 1.5123 - accuracy: 0.5451 - val_loss: 1.4828 - val_accuracy: 0.7192\n",
      "Epoch 8/10\n",
      "230/230 [==============================] - 173s 753ms/step - loss: 1.4771 - accuracy: 0.5840 - val_loss: 1.4373 - val_accuracy: 0.7301\n",
      "Epoch 9/10\n",
      "230/230 [==============================] - 1945s 8s/step - loss: 1.4282 - accuracy: 0.6188 - val_loss: 1.3734 - val_accuracy: 0.7381\n",
      "Epoch 10/10\n",
      "230/230 [==============================] - 115s 499ms/step - loss: 1.3608 - accuracy: 0.6467 - val_loss: 1.2834 - val_accuracy: 0.7529\n",
      "Training time: 1:19:30.878988\n",
      "Test loss score: 1.2834107875823975\n",
      "Test accuracy: 0.7529314756393433\n"
     ]
    }
   ],
   "source": [
    "train_model(model3,\n",
    "            (x_train_gte5, y_train_gte5),\n",
    "            (x_test_gte5, y_test_gte5), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze layers\n",
    "for l in feature_layers3:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 26, 26, 32)        9248      \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 12, 12, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 12, 12, 32)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 328)               1511752   \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 328)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 328)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 1645      \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,532,213\n",
      "Trainable params: 1,513,397\n",
      "Non-trainable params: 18,816\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (30596, 28, 28, 1)\n",
      "30596 train samples\n",
      "5139 test samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 30s 122ms/step - loss: 1.5344 - accuracy: 0.3726 - val_loss: 1.4905 - val_accuracy: 0.5057\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 29s 122ms/step - loss: 1.4722 - accuracy: 0.4474 - val_loss: 1.4218 - val_accuracy: 0.5489\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 29s 120ms/step - loss: 1.4097 - accuracy: 0.5120 - val_loss: 1.3557 - val_accuracy: 0.5941\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 39s 164ms/step - loss: 1.3523 - accuracy: 0.5724 - val_loss: 1.2922 - val_accuracy: 0.6951\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 58s 240ms/step - loss: 1.2924 - accuracy: 0.6456 - val_loss: 1.2310 - val_accuracy: 0.7840\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 53s 222ms/step - loss: 1.2373 - accuracy: 0.7060 - val_loss: 1.1727 - val_accuracy: 0.8336\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 51s 215ms/step - loss: 1.1846 - accuracy: 0.7525 - val_loss: 1.1171 - val_accuracy: 0.8581\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 51s 214ms/step - loss: 1.1338 - accuracy: 0.7917 - val_loss: 1.0639 - val_accuracy: 0.8751\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 51s 215ms/step - loss: 1.0831 - accuracy: 0.8165 - val_loss: 1.0134 - val_accuracy: 0.8864\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 55s 227ms/step - loss: 1.0372 - accuracy: 0.8363 - val_loss: 0.9660 - val_accuracy: 0.8953\n",
      "Training time: 0:07:27.364379\n",
      "Test loss score: 0.9659677743911743\n",
      "Test accuracy: 0.8953103423118591\n"
     ]
    }
   ],
   "source": [
    "train_model(model3,\n",
    "            (x_train_lt5, y_train_lt5),\n",
    "            (x_test_lt5, y_test_lt5), num_classes) # Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
